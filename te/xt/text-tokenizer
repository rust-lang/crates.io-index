{"name":"text-tokenizer","vers":"0.4.1","deps":[{"name":"lazy_static","req":"^1.1","features":[],"optional":false,"default_features":true,"target":null,"kind":"normal"},{"name":"regex","req":"^1","features":[],"optional":false,"default_features":true,"target":null,"kind":"normal"},{"name":"unicode-segmentation","req":"^1.2","features":[],"optional":false,"default_features":true,"target":null,"kind":"normal"},{"name":"unicode_categories","req":"^0.1","features":[],"optional":false,"default_features":true,"target":null,"kind":"normal"}],"cksum":"bb696b99716f53e8ba09ccbe476a3eee324cc9b9b9227efa6e163b987e760cd2","features":{"default":["strings"],"strings":[]},"yanked":false}
